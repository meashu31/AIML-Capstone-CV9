{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet_Models_Pneumonia.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Cbw-4DX8sTaphWllzjiDuO1bFrz7nO3T",
      "authorship_tag": "ABX9TyPsw4li1zZMv8N/txQ5u+QC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meashu31/AIML-Capstone-CV9/blob/Vadhi_master/Unet_Models_Pneumonia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDN7dCedAIXD",
        "colab_type": "text"
      },
      "source": [
        "## Mount Gogle Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cViY1pf-lIp8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9c4b981a-f73e-4ba1-cae3-56a484c7fe45"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4Yt6mOWlowf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "ae40fb1d-7652-44bb-c8e0-ec631e5d6853"
      },
      "source": [
        "pip install segmentation-models"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting segmentation-models\n",
            "  Downloading https://files.pythonhosted.org/packages/da/b9/4a183518c21689a56b834eaaa45cad242d9ec09a4360b5b10139f23c63f4/segmentation_models-1.0.1-py3-none-any.whl\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\n",
            "Collecting image-classifiers==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from segmentation-models) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.16.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.18.5)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.0.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.12.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.1)\n",
            "Installing collected packages: efficientnet, image-classifiers, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 segmentation-models-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2Wq2-hcmRqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.keras.utils import data_utils\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from keras.utils.layer_utils import count_params\n",
        "from tabulate import tabulate\n",
        "from segmentation_models import Unet\n",
        "from segmentation_models import get_preprocessing\n",
        "from segmentation_models.losses import bce_jaccard_loss\n",
        "from segmentation_models.metrics import iou_score\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from keras.layers import *\n",
        "from keras.models import *"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN9avMtzmP84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ee1d0e1f-d304-40b2-e37a-78654b2f8f5c"
      },
      "source": [
        "im_path = '/content/drive/My Drive/Capstone/data/images/'\n",
        "mask_path = '/content/drive/My Drive/Capstone/data/masks/'\n",
        "train_list = os.listdir(im_path)\n",
        "mask_list = os.listdir(mask_path)\n",
        "print(len(train_list))\n",
        "print(len(mask_list))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26684\n",
            "26684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AsKBDwGpJHx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "90efaa9c-bddf-420a-c1f7-ab411e4f5aaf"
      },
      "source": [
        "X_train, X_val = train_test_split(train_list[:100], test_size=0.20, random_state=53)\n",
        "print('Length of training data:',len(X_train),'\\nLength of validation data:',len(X_val))"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of training data: 80 \n",
            "Length of validation data: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v3QIYyAphzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(data_utils.Sequence):\n",
        "    \"\"\"Generates data for Keras\n",
        "    Sequence based data generator. Suitable for building data generator for training and prediction.\n",
        "    \"\"\"\n",
        "    def __init__(self, list_IDs, image_path, mask_path, batch_size=32, dim=(1024, 1024),n_channels=1, shuffle=True,resize=False, preprocess_input=preprocess_input):\n",
        "        \"\"\"Initialization\n",
        "        self.list_IDs = List of all unique patient Ids\n",
        "        self.image_path = path to image folder\n",
        "        self.mask_path = path to mask folder\n",
        "        self.batch_size = batch_size\n",
        "        self.dim = dimenstion for each input image\n",
        "        self.n_channels = no.of channels per image\n",
        "        self.resize = if true, will resize the input image to self.dim\n",
        "        self.shuffle = True to shuffle label indexes after every epoch\n",
        "        \"\"\"\n",
        "        self.list_IDs = list_IDs\n",
        "        self.TempList = list_IDs\n",
        "        self.image_path = image_path\n",
        "        self.mask_path = mask_path\n",
        "        self.batch_size = batch_size\n",
        "        self.dim = dim\n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "        self.resize = resize\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the number of batches per epoch\n",
        "        :return: number of batches per epoch\n",
        "        \"\"\"\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "        if len(list_IDs_temp)==0:\n",
        "          print('Trying to access an empty batch. No image left to iterate over. Try changing the batch index')\n",
        "          return None\n",
        "        else:\n",
        "          # Generate data\n",
        "          X, y = self.__pixel_generation(list_IDs_temp)\n",
        "\n",
        "          return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\n",
        "        \"\"\"\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __pixel_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim)\n",
        "        ''' Initialization\n",
        "         *self.dim is a variable length parameter. It can vary based on the size of image'''\n",
        "        \n",
        "        x_image = np.empty((self.batch_size, self.dim[0],self.dim[1],3))\n",
        "        x_channels = np.empty((self.dim[0],self.dim[1],3))\n",
        "        y_mask = np.empty((self.batch_size, *self.dim))\n",
        "        ID_List = []\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            if self.resize == True:\n",
        "              x_frame = Image.open(self.image_path + ID).resize((self.dim[0],self.dim[1]),Image.ANTIALIAS)\n",
        "              y_frame = Image.open(self.mask_path + ID).resize((self.dim[0],self.dim[1]),Image.ANTIALIAS)\n",
        "            else:\n",
        "              x_frame = Image.open(self.image_path + ID)\n",
        "              y_frame = Image.open(self.mask_path + ID)\n",
        "            #print(np.array(x_frame).dtype)\n",
        "            # Store images\n",
        "            for z in range(3):\n",
        "              x_channels[:,:,z] = np.array(x_frame)\n",
        "            \n",
        "            x_image[i,] = preprocess_input(np.array(x_channels, dtype=np.float32))\n",
        "            # Store masks\n",
        "            temp = np.array(y_frame)\n",
        "            temp = np.where(temp > 0 , 1, y_frame)           \n",
        "            y_mask[i,] = temp\n",
        "            # Store ID\n",
        "        return x_image, y_mask"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS0K7WC3p7uS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_gen = DataGenerator(list_IDs=X_train , image_path = im_path, mask_path=mask_path,dim=(224,224),batch_size=8,resize=True)\n",
        "X_Val_gen = DataGenerator(list_IDs=X_val , image_path = im_path, mask_path=mask_path,dim=(224,224),batch_size=8,resize=True)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ODT1cwlASER",
        "colab_type": "text"
      },
      "source": [
        "## Backboned-UNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VRzaOKCYn7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GetModel(Backbone='', pretrained=True,ShowSummery=False):\n",
        "  \"\"\" Loading backbone. \"\"\"\n",
        "  # TODO: More backbones\n",
        "  if Backbone == 'Vanilla_CNN':\n",
        "    print(\"Loading Vanilla CNN\")\n",
        "  elif Backbone == 'VGG_16':\n",
        "    create_model(Backbone='vgg16',pretrained=pretrained,ShowSummery=ShowSummery)\n",
        "  elif Backbone == 'vgg19':\n",
        "    create_model(Backbone='vgg19',pretrained=pretrained,ShowSummery=ShowSummery)\n",
        "  elif Backbone == 'resnet18':\n",
        "    create_model(Backbone='resnet18',pretrained=pretrained,ShowSummery=ShowSummery)\n",
        "  elif Backbone == 'resnet34':\n",
        "    create_model(Backbone='resnet34',pretrained=pretrained,ShowSummery=ShowSummery)\n",
        "  elif Backbone == 'Resnet-50':\n",
        "    create_model(Backbone='resnet50',pretrained=pretrained,ShowSummery=ShowSummery)\n",
        "  elif Backbone == 'resnet101':\n",
        "    create_model(Backbone='resnet101',pretrained=pretrained,ShowSummery=ShowSummery)\n",
        "  elif Backbone == 'resnet152':\n",
        "    create_model(Backbone='resnet152',pretrained=pretrained,ShowSummery=ShowSummery)\n",
        "  elif Backbone == 'DenseNet121':\n",
        "    create_model(Backbone='densenet121',pretrained=pretrained,ShowSummery=ShowSummery)\n",
        "  elif Backbone == 'DenseNet169':\n",
        "    create_model(Backbone='densenet169',pretrained=pretrained,ShowSummery=ShowSummery)\n",
        "  elif Backbone == 'DenseNet201':\n",
        "    create_model(Backbone='densenet201',pretrained=pretrained,ShowSummery=ShowSummery)\n",
        "  elif Backbone == 'inception_v3':\n",
        "    create_model(Backbone='inceptionv3',pretrained=pretrained,ShowSummery=ShowSummery)\n",
        "  elif Backbone == 'Inception_ResNet_V2':\n",
        "    create_model(Backbone='inceptionresnetv2',pretrained=pretrained,ShowSummery=ShowSummery)\n",
        "  elif Backbone == 'MobileNet':\n",
        "    create_model(Backbone='mobilenet',pretrained=pretrained)\n",
        "  else:\n",
        "    raise NotImplementedError('{} backbone model is not implemented so far.'.format(name))"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFn2TZ1hlS_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(Backbone='vgg16',pretrained=True,ShowSummery=False):\n",
        "  # preprocess input\n",
        "  preprocess_input = get_preprocessing(Backbone)\n",
        "  x_train = DataGenerator(list_IDs=X_train , image_path = im_path, mask_path=mask_path,dim=(224,224),batch_size=8,resize=True, preprocess_input=preprocess_input)\n",
        "  x_val = DataGenerator(list_IDs=X_val , image_path = im_path, mask_path=mask_path,dim=(224,224),batch_size=8,resize=True, preprocess_input=preprocess_input)\n",
        "\n",
        "  # define model\n",
        "  model = Unet(Backbone, encoder_weights='imagenet', input_shape=(224, 224, 3))\n",
        "  ##-------------------getLast layer and add reshape----------------------\n",
        "  LastLayerIdx = len(model.layers) - 1\n",
        "  LastLayerName = model.layers[LastLayerIdx].name\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = not pretrained\n",
        "    LastLayer = model.get_layer(LastLayerName).output\n",
        "    x = Reshape((224, 224))(LastLayer)\n",
        "  model = Model(inputs=model.input, outputs=x)\n",
        "  trainable_count = count_params(model.trainable_weights)\n",
        "  non_trainable_count = count_params(model.non_trainable_weights)\n",
        "\n",
        "  print(tabulate([['Model', 'UNet'],\\\n",
        "                          ['BackBone', Backbone],\\\n",
        "                          ['Total params', model.count_params()],\\\n",
        "                          ['Trainable params', trainable_count],\\\n",
        "                          ['Non-trainable params', non_trainable_count]],\\\n",
        "                          headers=['Header', 'Value'], tablefmt='orgtbl'))\n",
        "  if ShowSummery: model.summary()\n",
        "\n",
        "  model.compile('Adam', loss=bce_jaccard_loss, metrics=['accuracy',iou_score])\n",
        "  checkpoint = ModelCheckpoint(\"model-{loss:.2f}.h5\", monitor=\"loss\", verbose=1, save_best_only=True, save_weights_only=True, mode=\"min\", period=1)\n",
        "  stop = EarlyStopping(monitor=\"loss\", patience=5, mode=\"min\")\n",
        "\n",
        "  model.fit(X_train_gen,\n",
        "          epochs=1,\n",
        "          steps_per_epoch = len(X_train_gen)/2,\n",
        "          validation_data=X_Val_gen,\n",
        "          validation_steps = len(X_train_gen)/3*2,\n",
        "          callbacks= [checkpoint, stop])"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30cw-HKEqN5_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "565bac78-ee3c-4936-9255-05a7559cdbda"
      },
      "source": [
        "model = GetModel(Backbone='MobileNet',pretrained=True,ShowSummery=False)"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Header               | Value     |\n",
            "|----------------------+-----------|\n",
            "| Model                | UNet      |\n",
            "| BackBone             | mobilenet |\n",
            "| Total params         | 8336337   |\n",
            "| Trainable params     | 0         |\n",
            "| Non-trainable params | 8336337   |\n",
            "Epoch 1/1\n",
            "5/5 [==============================] - 26s 5s/step - loss: 2.0372 - accuracy: 0.0048 - iou_score: 4.0810e-11 - val_loss: 3.0995 - val_accuracy: 0.0000e+00 - val_iou_score: 2.9404e-11\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.03718, saving model to model-2.04.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7g5vc71A7sW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}