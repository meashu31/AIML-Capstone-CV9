# -*- coding: utf-8 -*-
"""ChexNet (3).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LF8McNLkyNrG2Jhblwghe3SOnRJC85Zr

## Mount Google drive to access images and masks
"""

from google.colab import drive
drive.mount('/content/drive/',force_remount=True)

!pip install pydicom

#Set the project path 
project_path =  '/content/drive/My Drive/AIML_Delete/Capstone/'

import os
os.chdir(project_path)
path = '.'

ls

TRAIN_IMAGES = os.path.join(project_path + 'stage_2_train_images/')
TEST_IMAGES = os.path.join(project_path + 'stage_2_test_images/')
OUTPUT_DIR = os.path.join(project_path + 'output/')
if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)

import pydicom 
from pydicom.data import get_testdata_files
import matplotlib.pyplot as plt
import pandas as pd
import cv2

import os
from sklearn.model_selection import train_test_split
from tensorflow.python.keras.utils import data_utils
import numpy as np
from PIL import Image
from keras.utils.layer_utils import count_params
from tabulate import tabulate

from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
import ipywidgets as widgets
import pandas as pd
from IPython.display import clear_output
import calendar
import time
import datetime
import matplotlib.pyplot as plt

from keras.layers import Input
from keras.models import Model
from keras.layers import Dense,Dropout,Flatten
from keras.optimizers import Adam
from keras.applications.densenet import DenseNet121
from keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
import keras
import random
from tqdm import tqdm

#from generator import DataGenerator

#Read pkl file with the feature engineered data
train_class = pd.read_pickle(project_path+'output/training_df.pkl')
display(train_class.shape, train_class.head())

TRAIN_IMAGES_DIR = os.path.join(project_path + 'stage_2_train_images_png/')
if not os.path.exists(TRAIN_IMAGES_DIR): os.makedirs(TRAIN_IMAGES_DIR)

# Store only paths , classes and targets to another dataframe
print('Prepare a dataframe with paths, classes and targets'); print('--'*40)
path_class_target = train_class[['PatientID', 'path', 'class', 'Target']].copy(deep = True)
path_class_target['path'] = (path_class_target['path']
                             .str.replace('stage_2_train_images', 'stage_2_train_images_png')
                             .str.replace('.dcm', '.png'))
path_class_target.drop_duplicates(inplace = True)
display(path_class_target.shape, path_class_target.nunique())
print('\nDistribution of target and classes')
display(path_class_target['Target'].value_counts())
print()
display(path_class_target['class'].value_counts())

# Split the data in train, valid and test sets

image_list = list(path_class_target['path'])
random.shuffle(image_list)
val_size = round(len(image_list)/10)

train_size = len(image_list)-val_size

X_train = image_list[:train_size]
X_valid = image_list[train_size:(train_size + val_size)]

# Create training and validation dataframes concatenated woth path and target class 

df_train = (path_class_target.merge(pd.Series(X_train, name = 'path'), 
                                    on = 'path', 
                                    how = 'right')
          .drop(['class', 'PatientID'], axis = 1))

df_valid = (path_class_target.merge(pd.Series(X_valid, name = 'path'), 
                                    on = 'path', 
                                    how = 'right')
          .drop(['class', 'PatientID'], axis = 1))


print('Shape of the dataframes:\nTRAIN:{}\nVALID:{}'.format(df_train.shape, df_valid.shape))

#Store train and test dataframes in pkl
df_train.to_pickle(OUTPUT_DIR + 'train_data.pkl')
df_valid.to_pickle(OUTPUT_DIR + 'valid_data.pkl')

df_train = pd.read_pickle(OUTPUT_DIR + 'train_data.pkl')
df_valid = pd.read_pickle(OUTPUT_DIR + 'valid_data.pkl')
display(df_train.shape, df_valid.shape)

"""# Generator for Images"""

# MODEL IMPORTS
import tensorflow as tf
assert tf.__version__ >= '2.0'
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard
from sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, Dropout, Flatten, Input
from tensorflow.keras.applications.densenet import preprocess_input
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.optimizers import Adam
from skimage.transform import resize
from imgaug import augmenters as iaa

import pydicom as dcm, cv2
from PIL import Image
import pandas as pd
import numpy as np
import keras
random_state = 2020


def roc_auc(y_true, y_pred):
    return tf.compat.v1.py_function(roc_auc_score, (y_true, y_pred), tf.double)


import tensorflow.keras.backend as K
def average_precision(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

# Augmenter
augmenter = ImageDataGenerator(preprocessing_function = preprocess_input, 
                               rotation_range = 20, width_shift_range = 0.2,
                               height_shift_range = 0.2, zoom_range = 0.2,
                               horizontal_flip = True)

# Data Generator
class DataGenerator(tf.keras.utils.Sequence):
    def __init__(self, dataset_df, img_dir, batch_size = 32, dim = (224, 224), 
                 transform = None, n_channels = 1, shuffle = True, debug = False):
        
        self.dataset_df = dataset_df
        self.paths = self.dataset_df['path']
        self.img_dir = img_dir 
        self.batch_size = batch_size
        self.dim = dim
        self.n_channels = n_channels
        self.shuffle = shuffle
        self.debug = debug
        self.transform = transform
        self.on_epoch_end()

    def __len__(self):
        return int(np.floor(len(self.dataset_df) / self.batch_size))

    def __getitem__(self,index):
        indexes = self.indexes[index*self.batch_size:(index + 1)*self.batch_size]    

        list_IDs_batch = [self.paths[k] for k in indexes]

        imgs, labels = self.__data_generation(list_IDs_batch)

        if self.debug: return list_IDs_batch, imgs, labels 
        else: return imgs, labels
    
    def on_epoch_end(self):
        self.indexes = np.arange(len(self.dataset_df))
        if self.shuffle == True: np.random.shuffle(self.indexes)
    
    def __data_generation(self, list_IDs_batch):
        imgs = np.empty((self.batch_size, *self.dim, self.n_channels))
        labels = np.empty((self.batch_size), dtype = int)
        for i, ID in enumerate(list_IDs_batch): 
            imgs[i,] = self.load_img(self.img_dir, ID, self.dim)
            labels[i] = self.get_label(ID)
        return imgs, labels
    
    def load_img(self, img_dir, path, dim):
        img = Image.open(path)
        img = np.asarray(img.convert('RGB'))
        img = img / 255.
        img = cv2.resize(img, dim)
        if not self.transform == None:
            params = self.transform.get_random_transform(img.shape)
            img = self.transform.apply_transform(img, params)
        return img
    
    def get_label(self, path):
        data_df = self.dataset_df.loc[self.dataset_df['path'] == path].values
        return int(data_df[0][1])

# Predictor
def predictor(model, validation_generator):
    y_pred = []
    y_roc = []
    y_true = []
    for i, batch in enumerate(validation_generator):
        imgs = batch[0]
        labels = batch[1]
        for img, label in zip(imgs, labels):
            img = np.expand_dims(img, axis = 0)
            pred = model.predict(img)
            y_roc.append(pred)
            if pred > 0.5: pred = 1
            else: pred = 0
            y_pred.append(pred)
            y_true.append(label)
    return y_true, y_pred, y_roc

"""# CheXNet Model"""

#hyper parameter
input_shape = (224, 224, 3)
num_of_class = 1

img_in = Input(input_shape)              #input of model 
model = DenseNet121(include_top= False , # remove  the 3 fully-connected layers at the top of the network
                weights='imagenet',      # pre train weight         
                input_tensor= img_in,      
                input_shape= input_shape,
                pooling ='avg') 
sample = int(len(model.layers)/3)
for layer in model.layers[:sample]:
  layer.trainable=True
for layer in model.layers[sample:]:
  layer.trainable=False

x = model.output  
#x1= Dense(num_of_class,activation="sigmoid", name="x1")(x)
x1 = Flatten()(x)
x1 = Dense(1024, activation = 'relu')(x1)
x2 = Dropout(0.5)(x1)
x3 = Dense(1024, activation = 'relu')(x2)
predictions = Dense(num_of_class,activation="sigmoid", name="predictions")(x3)    # fully connected layer for predict class 
#x1=tf.keras.layers.Reshape(((224, 224)))
model = Model(inputs=img_in, outputs=predictions)

model.summary()

"""## Model Execution"""

batch_size = 32
optimizer = Adam(lr=0.001)
model.compile(optimizer=optimizer, loss="binary_crossentropy", metrics=[keras.metrics.binary_accuracy,'accuracy', average_precision])
train_generator = DataGenerator(dataset_df = df_train, img_dir = TRAIN_IMAGES_DIR,
                                batch_size = batch_size, dim = (224, 224),
                                transform = augmenter, n_channels = 3, shuffle = True)

validation_generator = DataGenerator(dataset_df = df_valid, img_dir = TRAIN_IMAGES_DIR,
                                     batch_size = batch_size, dim = (224, 224),
                                     transform = ImageDataGenerator(preprocessing_function = preprocess_input), 
                                     n_channels = 3, shuffle = True)
history =model.fit_generator(generator=train_generator,
                    epochs = 5,
                    validation_data=validation_generator,
                    steps_per_epoch=24016//(batch_size*2),
                    validation_steps = 2668//(batch_size*2),
                    use_multiprocessing=True,
                    workers = 6)

# Saving the weights
MODEL_WEIGHTS = os.path.join(project_path + 'model_weights/')
if not os.path.exists(MODEL_WEIGHTS): os.makedirs(MODEL_WEIGHTS)
FINAL_MODEL = 'chexnet_final.h5'

model.save(MODEL_WEIGHTS + FINAL_MODEL)

import math
validation_generator = DataGenerator(dataset_df = df_valid, img_dir = TRAIN_IMAGES_DIR,
                                     batch_size = batch_size * 2, dim = (224, 224),
                                     transform = ImageDataGenerator(preprocessing_function = preprocess_input), 
                                     n_channels = 3, shuffle = False)

loss, accuracy, ap = model.evaluate_generator(generator = validation_generator, 
                                              steps = 2668//(batch_size**2))
print(f'Loss: {round(loss, 3)}, Accuracy: {round(float(accuracy), 3)}, AP: {round(float(ap), 3)}')
